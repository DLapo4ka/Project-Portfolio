{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Segmentation of the customer database and behavioral profiling\n",
    "## By Daria Lapko, Konstantin Shashkov, Timofey Sluev. DSBA 201\n",
    "### Data Analysis in Business"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's import the necessary modules first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmatplotlib\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minline\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2417\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2415\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2416\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2417\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2419\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2420\u001B[0m \u001B[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2421\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:99\u001B[0m, in \u001B[0;36mPylabMagics.matplotlib\u001B[1;34m(self, line)\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAvailable matplotlib backends: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m backends_list)\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 99\u001B[0m     gui, backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menable_matplotlib\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgui\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgui\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgui\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_show_matplotlib_backend(args\u001B[38;5;241m.\u001B[39mgui, backend)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3588\u001B[0m, in \u001B[0;36mInteractiveShell.enable_matplotlib\u001B[1;34m(self, gui)\u001B[0m\n\u001B[0;32m   3567\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21menable_matplotlib\u001B[39m(\u001B[38;5;28mself\u001B[39m, gui\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   3568\u001B[0m     \u001B[38;5;124;03m\"\"\"Enable interactive matplotlib and inline figure support.\u001B[39;00m\n\u001B[0;32m   3569\u001B[0m \n\u001B[0;32m   3570\u001B[0m \u001B[38;5;124;03m    This takes the following steps:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3586\u001B[0m \u001B[38;5;124;03m        display figures inline.\u001B[39;00m\n\u001B[0;32m   3587\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3588\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib_inline\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend_inline\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m configure_inline_support\n\u001B[0;32m   3590\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pylabtools \u001B[38;5;28;01mas\u001B[39;00m pt\n\u001B[0;32m   3591\u001B[0m     gui, backend \u001B[38;5;241m=\u001B[39m pt\u001B[38;5;241m.\u001B[39mfind_gui_and_backend(gui, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpylab_gui_select)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib_inline\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend_inline, config  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m      2\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.1.6\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Copyright (c) IPython Development Team.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m colors\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackends\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend_agg\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 1. Data exploration\n",
    "<hr color=green>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we need to read the data\n",
    "df_base = pd.read_excel(\"data.xlsx\")\n",
    "df = df_base.copy(deep=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View some data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Observe some data information\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can observe that the data presents a set of orders of an online store. It consists of 356017 entries and 22 fields, including the ones describing the product type, the customer's contacts, the order status, delivery information, and timing. Each record contains the following datatypes: 1 datetime field (*OrderDate*), 9 int64 fields, and 12 object fields, which constitute to the string data that could not be automatically parsed to any standard Pandas datatype."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Missing values\n",
    "\n",
    "Let us print the number of missing values accross different columns and their percentage among all data in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the missing values\n",
    "df_nan = pd.DataFrame({})\n",
    "df_nan[\"# empty (NaN)\"] = df.isna().sum()\n",
    "df_nan[\"% empty (NaN)\"] = df.isna().sum()/df[df.columns[0]].count()*100\n",
    "df_nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The printout above shows that only 64 rows out of 356017 contain missing values. The percentage on the right shows that this number is negligibly small, so one can remove such records without any significant impact on the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Duplicated records\n",
    "Every record represents an order to the online store. The field *Order_ID* should be uniquely defined for every order and vice-versa. Hence, all similar records should be dropped from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Now, consider the numeric and categorical variables (as automatically predetected) separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate numerical data from categorical data\n",
    "data_num = df.select_dtypes(exclude=['object', 'datetime64'])\n",
    "data_cat = df.select_dtypes(include=['object', 'datetime64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_cat.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Consider the categorical variables first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Review the number of categorical unique values\n",
    "df_cat_info = pd.DataFrame({})\n",
    "df_cat_info[\"# unique\"] = data_cat.nunique(dropna=False)\n",
    "df_cat_info[\"% unique\"] = data_cat.nunique()/data_cat[data_cat.columns[0]].count()*100\n",
    "df_cat_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "According to the table above, the highest number of unique values is found in *Order_ID* and *Phone_new* column, while *Source* and *Delivery* type have the lowest number."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we shall print the values of different categorical variables to check them one by one for possible issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the unique values\n",
    "uniq_vals = pd.DataFrame()\n",
    "for i in data_cat.columns:\n",
    "    print(i)\n",
    "    print(pd.unique(data_cat[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Firstly, we spotted repetitions and similar values in *CancelReason*. Let us merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Group cancel reasons\n",
    "df[\"CancelReason\"] = df['CancelReason'].replace('Витринный образец/Брак товара', \"Витрина/брак/некондиция/качество товара\")\n",
    "df[\"CancelReason\"] = df['CancelReason'].replace('Качество товара', \"Витрина/брак/некондиция/качество товара\")\n",
    "df[\"CancelReason\"] = df['CancelReason'].replace('Не устроило время доставки', \"Не устроили дата/время доставки\")\n",
    "df[\"CancelReason\"] = df['CancelReason'].replace('Не устроила дата доставки', \"Не устроили дата/время доставки\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It was also found that names of some variables are not completely understandable and do not convey the meaning of this variable. Hence, we shall rename them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make names sensible\n",
    "df.rename(columns={\"NomGroup\": \"Item\", \"TN\": \"Category\", \"TK\": \"Type\"}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Right now columns stand in not a very conveninent order. We propose to swap *Category* and *Type* (right now we consider only categorical-type columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reindex dataframe\n",
    "df = df.reindex(columns=df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Remove \"Доставка\" column. Since it is added to most of the orders and breaks the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop to avoid multicollinearilty\n",
    "df = df.drop(df[df[\"Item\"] == \"Доставка\"].index)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, we've seen that some variables contradict each other, and so we should delete such rows so not to mess up during further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bad Status, No Cancel Reason\n",
    "df = df.drop(df[((df['Status'] == 'Отменен') | (df['Status'] == 'Отказ на месте')) & (df['CancelReason'] == 'Не отменен')].index)\n",
    "\n",
    "# Good Status, Bad Cancel Reason\n",
    "df = df.drop(df[((df['Status'] != 'Отменен') & (df['Status'] != 'Отказ на месте')) & (df['CancelReason'] != 'Не отменен')].index)\n",
    "\n",
    "# Bad DeliveryType, No Cancel Reason\n",
    "df = df.drop(df[(df['DeliveryType'] == 'Заказ отменен') & (df['CancelReason'] == 'Не отменен')].index)\n",
    "\n",
    "# Bad DeliveryType, Good Status\n",
    "df = df.drop(df[(df['DeliveryType'] == 'Заказ отменен') & ((df['Status'] != 'Отменен') & (df['Status'] != 'Отказ на месте'))].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For visual representation and to better understand the data contents, we build the graphs and charts of several variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pie chart of ways to receive an order\n",
    "plt.pie(df['DeliveryType'].value_counts(), labels=df['DeliveryType'].unique(), pctdistance=.7, autopct='%1.1f%%')\n",
    "plt.title(\"Pie chart of ways to receive an order\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It is clearly seen from the pie chart that more than 3/4 of people chose delivery when making an order. About one fifth of all customers canceled their order, and only a very small part took self pickup.\n",
    "\n",
    "Important note: the fact that about 20% of orders according to the chart were canceled does not mean this is the real number of orders canceled. As we can see from the initial table, there exist orders which were assigned to delivery/pickup but had status \"Отменен\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bar chart of payment types\n",
    "fig, ax = plt.subplots(figsize=(17,5))\n",
    "sns.barplot(y=df['PaymentType'].unique(), x=df['PaymentType'].value_counts())\n",
    "plt.title(\"Bar chart of payment types\")\n",
    "plt.ylabel(\"Payment type\")\n",
    "plt.xlabel(\"Count\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looking at the bar chart above we can see that most of the orders were paid by cash: more than 250 000 cases of such. The second popular way to pay is by card when receiving the order: about 50 000 cases. The least popular ways are through Tinkoff bank and PayPal system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Countplot of orders in different categories\n",
    "sns.countplot(data=df, y='Category', order=df['Category'].value_counts(ascending=False).index)\n",
    "plt.title(\"Horizontal count plot of orders in different categories\")\n",
    "plt.xlabel(\"Count\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The last plot shows us that the greatest amount of things is bought in category \"Услуги\". This is simply because this category includes delivery, which is paid and goes with almost every other category, as we have seen in pie chart before. Looking at the real items, the most is bought in \"Мелкая бытовая техника\" (about 40 000) and \"Крупная бытовая техника\" (about 30 000), while the least in \"Инсталляция\" and \"Автотовары\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Region count by category\n",
    "plt.figure(figsize= (10,10))\n",
    "sns.countplot(data=df, order=df[\"Region\"].value_counts(ascending=False).index, x=\"Region\", hue=\"Category\", dodge=False, palette=\"tab20\")\n",
    "plt.title('Region Count by Category');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categories in SpB and LenOblast\n",
    "plot_data_lenobl = df[df['Субъект']=='Ленинградская обл.']\n",
    "plot_data_spb = df[df['Субъект']=='Санкт-Петербург']\n",
    "plot_data1 = pd.concat([plot_data_spb, plot_data_lenobl])\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=plot_data1, y='Category', order=df[\"Category\"].value_counts(ascending=False).index)\n",
    "plt.title(\"Categories Bought in St. Petersburg and Leningrad Region\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categories in Moscow\n",
    "plot_data = df[df['Субъект']=='Москва']\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=plot_data, y='Category', order=df[\"Category\"].value_counts(ascending=False).index)\n",
    "plt.title(\"Categories Bought in Moscow\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Order time distribution\n",
    "sns.histplot(data = df, x = 'Время заказа в часах')\n",
    "plt.xlabel(\"Order time\")\n",
    "plt.title(\"Order time distribution\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Unfortunately, *OrderDate* cannot be encoded as categorical variable, so we should invent another way to present time data. We decided to divide date on day number, month number and weekday. Three new columns with therefore appear instead of *OrderDate*: *dayNum*, *monthNum*, and *weekdayNum*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode datetime\n",
    "df[\"dayNum\"] = df[\"OrderDate\"].dt.day\n",
    "df[\"monthNum\"] = df[\"OrderDate\"].dt.month\n",
    "df[\"weekdayNum\"] = df[\"OrderDate\"].dt.weekday\n",
    "date = df[\"OrderDate\"]\n",
    "df = df.drop(columns = \"OrderDate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The *Phone_new* column is deleted from the data frame because it cannot be used for modelling (is categorical but cannot be encoded normally), but its data is saved in a numeric way (frequency of purchases) for future use in RFM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Work with Phone_new category\n",
    "countBuy = df['Phone_new'].map(df['Phone_new'].value_counts())\n",
    "df = df.drop(columns = \"Phone_new\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Now consider the numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider the numeric features\n",
    "df_numeric = pd.DataFrame({})\n",
    "df_numeric[\"mean\"] = data_num.mean()\n",
    "df_numeric[\"median\"] = data_num.median()\n",
    "df_numeric[\"min\"] = data_num.min()\n",
    "df_numeric[\"max\"] = data_num.max()\n",
    "df_numeric[\"sd\"] = data_num.std()\n",
    "df_numeric[\"# unique\"] = data_num.nunique(dropna=False)\n",
    "df_numeric[\"% unique\"] = data_num.nunique()/data_num[data_num.columns[0]].count()*100\n",
    "df_numeric[\"# zero\"] = data_num.agg(lambda x: x.eq(0).sum())\n",
    "df_numeric[\"% zero\"] = data_num.agg(lambda x: x.eq(0).sum())/data_num[data_num.columns[0]].count()*100\n",
    "df_numeric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The information above tells us general information about every single numeric variable. For example, we can see that median number of items bought of 1 type is 1, while maximum number is 285; the mean row price is 5123.02 while standard deviation is 10737.78; etc. We can also spot that there is a variable with binary (0 and 1) values only: *OneClick*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "correlation_mat = data_num.corr()\n",
    "plt.figure(figsize=(12,10), dpi=80)\n",
    "sns.heatmap(correlation_mat, annot = True, fmt=\".2f\")\n",
    "plt.title(\"Correlation matrix\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "According to the correlation matrix printed above, most of the numeric variables do not correlate (have neglibile values that range from -0.10 to 0.10). High positive correlation is spotted between *Week* and *месяц*, *RowSum* and *RowPrice*; small to medium correlation is between *RowPrice* and *RowDiscount*, *RowSum* and *RowDiscount*. All these correlations are explainable: *RowSum* includes *RowDiscount* and *RowPrice*, while *месяц* and *Week* are date variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It was spotted that *месяц* variable is not informative since we already have *OrderDate* which contains year, month and day of order. Hence, we can delete this column from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove multicollinearity\n",
    "df = df.drop(columns=\"месяц\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Product categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Consider a table of product categories to have a better understnading of the store's assortment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_categories = data_cat[['TN', 'TK', 'NomGroup']].drop_duplicates().sort_values(by=['TN', 'TK'])\n",
    "product_categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Before moving on to models, we ought to prepare a new data frame, which will not include cofusing data for the algorithms. The columns *Order_ID* and *Store_ID* do own such data, and even though it is important in general we cannot utilize it in modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data = data.drop(columns=[\"Order_ID\", \"Store_ID\"])\n",
    "data_initial = data.copy()\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To prepare categorical data for making models we ought to perform encoding of variables. We chose one-hot encoding because this is one of the easiest and most popular encodings, and also because no other encodings is suitable here (e.g. ordinal encoding: data in variables cannot be ordered here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "data = pd.get_dummies(data, columns = categorical_cols)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_scaled = MinMaxScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pca = PCA(n_components=0.8, random_state=42).fit_transform(data_scaled)\n",
    "data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sse = []\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    kmeans.fit(data_pca)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 10), sse)\n",
    "plt.xticks(range(1, 10))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.title('Elbow Method Analysis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KMeans(init=\"random\", n_clusters=5, n_init=10, random_state=1)\n",
    "model.fit(data_pca)\n",
    "fitted = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.unique(fitted)\n",
    "centroids = model.cluster_centers_\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in labels:\n",
    "     plt.scatter(data_pca[fitted == i , 0] , data_pca[fitted == i , 1] , label = i)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')\n",
    "plt.legend()\n",
    "plt.title('K-Means clustering');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_numclus = pd.DataFrame({})\n",
    "df_numclus[\"% data\"] = np.unique(fitted, return_counts=True)[1]/df.shape[0]\n",
    "df_numclus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_sampled = data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_scaled = MinMaxScaler().fit_transform(data_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pca = PCA(n_components=0.8, random_state=42).fit_transform(data_scaled)\n",
    "data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=1.8).fit(data_pca)\n",
    "np.unique(dbscan.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.unique(dbscan.labels_)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in labels:\n",
    "     plt.scatter(data_pca[dbscan.labels_ == i , 0] , data_pca[dbscan.labels_ == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.title('DBSCAN clustering');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### BIRCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "brc = Birch(n_clusters=3)\n",
    "birch_labels = brc.fit_predict(data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brcl = np.unique(birch_labels)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in brcl:\n",
    "     plt.scatter(data_pca[birch_labels == i , 0] , data_pca[birch_labels == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.title('BIRCH clustering');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_RFM = data.copy()\n",
    "date = date.apply(lambda x : x.timestamp()).astype(int)\n",
    "df_RFM[\"OrderDate\"] = date\n",
    "df_RFM[\"NumOrders\"] = countBuy\n",
    "df_RFM_overview = pd.DataFrame({})\n",
    "df_RFM_overview[\"mean\"] = round(df_RFM[[\"OrderDate\", \"NumOrders\", \"RowSum\"]].mean(),2)\n",
    "df_RFM_overview[\"min\"] = df_RFM[[\"OrderDate\",\"NumOrders\", \"RowSum\"]].min()\n",
    "df_RFM_overview[\"max\"] = df_RFM[[\"OrderDate\",\"NumOrders\", \"RowSum\"]].max()\n",
    "df_RFM_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantiles = round(df_RFM[[\"OrderDate\", \"NumOrders\", \"RowSum\"]].quantile([1.0/3.0, 2.0/3.0]),0).to_dict()\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def R_score(x):\n",
    "    if x <= quantiles['OrderDate'][1.0/3.0]:\n",
    "        return 1\n",
    "    elif x <= quantiles['OrderDate'][2.0/3.0]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def FM_score(x, y):\n",
    "    if x <= quantiles[y][1.0/3.0]:\n",
    "        return 3\n",
    "    elif x <= quantiles[y][2.0/3.0]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_RFM['R'] = df_RFM['OrderDate'].apply(lambda x: R_score(x))\n",
    "df_RFM['F'] = df_RFM['NumOrders'].apply(lambda x: FM_score(x, 'NumOrders'))\n",
    "df_RFM['M'] = df_RFM['RowSum'].apply(lambda x: FM_score(x, 'RowSum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_RFM['RFMScore'] = df_RFM['R'].map(str) + df_RFM['F'].map(str) + df_RFM['M'].map(str)\n",
    "df_RFM['RFMScore'] = df_RFM['RFMScore'].astype(int)\n",
    "df_RFM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "df_RFM.groupby('RFMScore').agg('NumOrders').mean().plot(kind='bar')\n",
    "plt.title(\"Mean Values of Recency vs RFM Score\")\n",
    "plt.ylabel(\"Secs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RFMcluster(lower, upper):\n",
    "    return df_RFM.loc[(df_RFM['RFMScore'] >= lower) & (df_RFM['RFMScore'] <= upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFM_1 = RFMcluster(111,133)\n",
    "RFM_2 = RFMcluster(211,233)\n",
    "RFM_3 = RFMcluster(311,333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([RFM_1[\"RFMScore\"].mode(), RFM_2[\"RFMScore\"].mode(), RFM_3[\"RFMScore\"].mode()]).dropna().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Hence, our targets for analysis are the following segments: **132**, **232**, **332**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Clustering interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ser = pd.Series(fitted)\n",
    "data_initial = data_initial.assign(K_means = fitted)\n",
    "data_initial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### K-Means clustering interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_kmeans = pd.DataFrame({})\n",
    "for col in data_initial.select_dtypes(exclude=['object', 'datetime64']):\n",
    "    df_kmeans[col] = round(data_initial[col].groupby(data_initial[\"K_means\"]).mean(),2)\n",
    "df_kmeans = df_kmeans.drop(columns=\"K_means\")\n",
    "df_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(8,15))\n",
    "cnt = 0\n",
    "for i in data_initial[\"DeliveryType\"].unique():\n",
    "    sns.countplot(data=data_initial[data_initial[\"DeliveryType\"] == i], x=\"K_means\", ax=ax[cnt])\n",
    "    if (cnt == 0):\n",
    "        ax[cnt].title.set_text('Delivery Type Count by Cluster');\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_initial[\"DeliveryType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=data_initial, y=\"CancelReason\")\n",
    "plt.title('Cancel Reason Values Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=data_initial[data_initial[\"CancelReason\"] == \"Не отменен\"], x=\"K_means\")\n",
    "plt.title('Completed Orders Count by Cluster');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=data_initial[data_initial[\"K_means\"] == 2], order=data_initial[\"CancelReason\"].value_counts(ascending=False).index, y=\"CancelReason\")\n",
    "plt.title('Cancel Reason Values Count in 2nd Cluster');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(7, 1, figsize=(8,13))\n",
    "cnt = 0\n",
    "print(data_initial[\"PaymentType\"].unique())\n",
    "for i in data_initial[\"PaymentType\"].unique():\n",
    "    sns.countplot(data=data_initial[data_initial[\"PaymentType\"] == i], x=\"K_means\", ax=ax[cnt], label=i)\n",
    "    if (cnt == 0):\n",
    "        ax[cnt].title.set_text('Payment Type Count by Cluster');\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,15))\n",
    "sns.countplot(data=data_initial, order=data_initial[\"Город\"].value_counts(ascending=False).index, y=\"Город\", hue=\"K_means\", dodge=False)\n",
    "plt.title('City Count by Cluster');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### RFM clustering interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_initial = data_initial.assign(RFMScore = df_RFM[\"RFMScore\"])\n",
    "data_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_initial = data_initial.loc[(df_RFM['RFMScore'] == 132) | (df_RFM['RFMScore'] == 232) | (df_RFM['RFMScore'] == 332)]\n",
    "df_RFMseg = pd.DataFrame({})\n",
    "for col in data_initial.select_dtypes(exclude=['object', 'datetime64']):\n",
    "  df_RFMseg[col] = round(data_initial[col].groupby(data_initial[\"RFMScore\"]).mean(),2)\n",
    "df_RFMseg = df_RFMseg.drop(columns=[\"K_means\",\"RFMScore\"])\n",
    "df_RFMseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,15))\n",
    "sns.countplot(data=data_initial, y=\"Region\", palette='bright', hue=\"RFMScore\", dodge=True)\n",
    "plt.title('Region Count by Cluster');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,15))\n",
    "sns.countplot(data=data_initial, order=data_initial[\"Type\"].value_counts(ascending=False).index, y=\"Type\", hue=\"RFMScore\", dodge=False)\n",
    "plt.title('Type Count by Cluster');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,15))\n",
    "sns.countplot(data=data_initial, order=data_initial[\"Category\"].value_counts(ascending=False).index, y=\"Category\", hue=\"RFMScore\", dodge=False)\n",
    "plt.title('Category Count by Cluster');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,15))\n",
    "sns.countplot(data=data_initial, x=\"weekdayNum\", hue=\"RFMScore\", palette=\"bright\")\n",
    "plt.title('Week Day Count by Cluster');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
